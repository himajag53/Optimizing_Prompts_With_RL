# Question-Answering Config
defaults:
  - base_qa
  - _self_
# Data
dataset: "squad"
# Reward
task_lm: "gpt2"
compute_zscore: True
# Single Prompt Model
prompt_length: 10
prompt_train_batch_size: 5
prompt_infer_batch_size: 16
# LM Adaptor Model
logit_bias: -10
task: 'question-answering'
# SQL Module
reward_shaping_old_min: 0
reward_shaping_old_max: 1
reward_shaping_new_min: -20
reward_shaping_new_max: 80
top_k: 5
# Trainer
train_batch_size: 5
max_train_steps: 10000
train_shuffle: false
eval_batch_size: 16
eval_steps: 100
save_steps: 1000
learning_rate: 5e-5
random_seed: null
report_to_wandb: false